# Main application file for AI Research Assistant
import streamlit as st
from typing import TypedDict, List
from langgraph.graph import END, StateGraph
from fpdf import FPDF
from agents import *
from config import *

# Define state schema
class AgentState(TypedDict):
    query: str
    research_data: List[dict]
    answer: str
    fact_checks: List[str]
    final_checks: List[str]
    professional_report: str
    agent_conversation: List[str]
    current_iteration: int
    max_iterations: int
    research_depth: str

def create_workflow():
    """Create and configure the research workflow graph."""
    workflow = StateGraph(AgentState)
    workflow.add_node("researcher", research_agent)
    workflow.add_node("drafter", answer_drafter_agent)
    workflow.add_node("fact_checker", fact_checker_agent)
    workflow.add_node("corrector", corrector_agent)
    workflow.add_node("validator", validation_agent)
    workflow.add_node("reporter", report_generator_agent)
    
    workflow.set_entry_point("researcher")
    
    workflow.add_conditional_edges(
        "researcher",
        lambda state: "drafter" if state["current_iteration"] >= state["max_iterations"] else "researcher",
        {"researcher": "researcher", "drafter": "drafter"}
    )
    
    workflow.add_edge("drafter", "fact_checker")
    
    workflow.add_conditional_edges(
        "fact_checker",
        lambda state: "corrector" if any("‚ùå" in check for check in state["fact_checks"])
        and state["current_iteration"] < state["max_iterations"]
        else "validator",
        {"corrector": "corrector", "validator": "validator"}
    )
    
    workflow.add_edge("corrector", "researcher")
    
    workflow.add_conditional_edges(
        "validator",
        lambda state: "corrector" if any("‚ùå" in check for check in state["final_checks"])
        and state["current_iteration"] < state["max_iterations"]
        else "reporter",
        {"corrector": "corrector", "reporter": "reporter"}
    )
    
    workflow.add_edge("reporter", END)
    
    return workflow.compile()

def generate_pdf(report_text: str) -> bytes:
    """Generate PDF from markdown report text."""
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    for line in report_text.split("\n"):
        pdf.multi_cell(0, 10, txt=line)
    pdf_output = pdf.output(dest="S").encode("latin1")
    return pdf_output

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# UI Configuration
st.title("üîç AI Research Assistant")
with st.sidebar:
    query = st.text_input("Research Query:", key="query_input")
    iterations = st.slider("Research Iterations", MIN_ITERATIONS, MAX_ITERATIONS, DEFAULT_ITERATIONS,
                         help="Total research cycles including corrections")
    research_depth = st.selectbox(
        "Depth Level",
        RESEARCH_DEPTH_OPTIONS,
        help="Determines search intensity and analysis depth"
    )

col1, col2 = st.columns([3, 1])

# Main Execution
if st.button("Start Research") and query:
    try:
        research_state = {
            "query": query,
            "research_data": [],
            "answer": "",
            "fact_checks": [],
            "final_checks": [],
            "professional_report": "",
            "agent_conversation": [],
            "current_iteration": 0,
            "max_iterations": iterations,
            "research_depth": research_depth
        }
        app = create_workflow()
        result = app.invoke(research_state)
        
        with col1:
            st.subheader("Research Report")
            st.markdown(result["answer"])
            with st.expander("**Verification Details**"):
                if result["fact_checks"]:
                    st.markdown("\n".join(result["fact_checks"]))
                else:
                    st.info("All claims verified successfully")
            st.subheader("Professional Research Report")
            with st.expander("üìÑ Table of Contents", expanded=True):
                toc = []
                for line in result["professional_report"].split("\n"):
                    if line.startswith("# "):
                        toc.append(f"- {line[2:]}")
                    elif line.startswith("## "):
                        toc.append(f"  - {line[3:]}")
                    elif line.startswith("### "):
                        toc.append(f"    - {line[4:]}")
                st.markdown("\n".join(toc))
            st.markdown(result["professional_report"])
            
            report_txt = f"{result['professional_report']}\n\nGenerated by AI Research System"
            st.download_button("üì• Download Full Report (Markdown)", report_txt, file_name="professional_report.md")
            
            pdf_bytes = generate_pdf(result["professional_report"])
            st.download_button("üì• Download Full Report (PDF)", data=pdf_bytes, file_name="professional_report.pdf", mime="application/pdf")
        
        with col2:
            progress = result["current_iteration"] / result["max_iterations"]
            st.progress(min(1.0, progress))
            st.metric("Total Sources", len(result["research_data"]))
            st.metric("Completed Iterations", f"{result['current_iteration']}/{result['max_iterations']}")
            st.metric("Remaining Issues", len([x for x in result["fact_checks"] if '‚ùå' in x]))
    
    except Exception as e:
        st.error(f"Research failed: {str(e)}")
        st.stop()

# Research Process Log
with st.container():
    st.subheader("Research Process Log")
    page_number = st.number_input(
        "Page", min_value=1, value=1, step=1, help="Navigate through agent messages"
    )
    start_idx = (page_number - 1) * PAGE_SIZE
    end_idx = start_idx + PAGE_SIZE
    for msg in st.session_state.messages[start_idx:end_idx]:
        with st.chat_message(msg["role"]):
            st.markdown(f"{msg['icon']} **{msg['role']}**: {msg['content']}")